{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26200dff-32c6-4a17-b3e4-f0c6c48603ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#1.确定这几个数据都是干什么的\n",
    "swiping_card_dataframe = pd.read_csv('./bus_swiping_card_info1.csv')\n",
    "card_info_dataframe = pd.read_csv('./card_info.csv')\n",
    "bus_swip_dataframe = pd.read_excel('公交数据.xlsx',sheet_name='刷卡数据',header=0,engine='openpyxl')\n",
    "bus_station_dataframe = pd.read_excel('公交数据.xlsx',sheet_name='站点数据',header=0,engine='openpyxl')\n",
    "#swiping_card_dataframe ： 每次刷卡的信息：几号线，第几站，车辆的id，刷卡的id，刷卡的时间\n",
    "#card_info_dataframe ： 每次刷卡的信息：几号线，第几站，车辆的id，刷卡的id，刷卡的时间也是上面的信息，但是时间是去年的。\n",
    "#用去年的时间的同比数据，去预测今年的同比数据，看是否一致，如果一致，说明经济发展没有变化，如果变大，说明经济好转\n",
    "#bus_swip_dataframe ：一天的统计信息：各条线路、各个站点的刷卡数量信息\n",
    "#bus_station_dataframe ： 站点的统计信息：各个站点的经纬度\n",
    "station_lat_lon_dataframe = bus_station_dataframe.groupby('station_name').agg({'latitude':list,'longitude':list}).reset_index()\n",
    "station_lat_lon_dataframe['lat'] = station_lat_lon_dataframe['latitude'].apply(lambda x:x[0])\n",
    "station_lat_lon_dataframe['lon'] = station_lat_lon_dataframe['longitude'].apply(lambda x:x[0])\n",
    "station_lat_lon_dataframe.drop(labels=['latitude','longitude'],axis=1,inplace=True)\n",
    "station_lat_lon_dataframe['lat_lon']=station_lat_lon_dataframe.apply(lambda x:(x['lat'],x['lon']),axis=1)\n",
    "station_lat_lon_dataframe.drop(labels=['lat','lon'],axis=1,inplace=True)\n",
    "station_lat_lon_ndarray = station_lat_lon_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f191be-8d49-4786-b15e-e3e4ab5caf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_lat_lon_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972aa5e-3119-493f-81f4-f920d4a66cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_sequence_ndarray = station_lat_lon_dataframe['station_name'].values\n",
    "station_sequence_ndarray\n",
    "import numpy as np\n",
    "np.savetxt('./station_sequence_ndarray.txt',station_sequence_ndarray,fmt='%s')\n",
    "station_nums_setting = len(station_sequence_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1e6e3-6b30-469d-860b-b4dfa186f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from geopy import distance\n",
    "iters=0\n",
    "station_pair_distance=[]\n",
    "station_pair_distance_temp=[]\n",
    "for station_pair_instance in itertools.product(station_lat_lon_ndarray,station_lat_lon_ndarray):\n",
    "    station_0 = station_pair_instance[0]\n",
    "    station_1 = station_pair_instance[1]\n",
    "    station_0_position = station_0[1]\n",
    "    station_1_position = station_1[1]\n",
    "    dist = distance.distance(station_0_position,station_1_position).m\n",
    "    if iters % station_nums_setting==0:\n",
    "        if iters!=0:\n",
    "            station_pair_distance.append(station_pair_distance_temp)\n",
    "        station_pair_distance_temp=[]\n",
    "        station_pair_distance_temp.append(dist)\n",
    "    else:\n",
    "        station_pair_distance_temp.append(dist)\n",
    "    iters +=1\n",
    "print(station_pair_distance[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b456ae4-286f-4232-aace-29479f3390df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# 保存列表到文件中\n",
    "with open('./station_pair_distance.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(station_pair_distance)\n",
    "print(\"文件保存成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2cc85-a44d-4ca0-b20d-4de35de364d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_pair_distance_ndarray = np.array(station_pair_distance)\n",
    "# 找出每行最小的k个值所对应的索引\n",
    "station_distance_rank_index_list = [sorted(range(len(row)), key=lambda i: row[i]) for row in station_pair_distance_ndarray]\n",
    "# 保存列表到文件中\n",
    "with open('./station_pair_distance_rank_index.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(station_distance_rank_index_list)\n",
    "print(\"文件保存成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48deba60-a137-49ad-9dad-3dcdc6907b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_sequence_ndarray = station_lat_lon_dataframe['station_name'].values\n",
    "station_sequence_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70889cc4-411f-45f8-997e-cb3d7787b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建字典并填充数据\n",
    "station_2_id = {value: index for index, value in enumerate(station_sequence_ndarray)}\n",
    "station_2_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba08d56-7548-47e8-b4e2-a1895dba3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建字典并填充数据\n",
    "id_2_station = {index: value for index, value in enumerate(station_sequence_ndarray)}\n",
    "id_2_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840a8a3-40b7-4b92-a7ac-6e3a88750957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# 将字典保存到文件中\n",
    "with open('./id_2_station.json', 'w') as file:\n",
    "    json.dump(id_2_station, file)\n",
    "# 将字典保存到文件中\n",
    "with open('./station_2_id.json', 'w') as file:\n",
    "    json.dump(station_2_id, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
